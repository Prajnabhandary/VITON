# Product Enrichment using GenAI

Table of Contents

- [Introduction](#introduction)
- [Solution Architecture](#solution-flow)
- [Models Used](#models-used)
- [Installation](#installation)
- [Configuration](#configuration)
- [Results](#results)

## Introduction

The objective of the project is to create enriched product image by using Computer Vision & Generative AI capabilities. The plain background image of the product is taken as input along with a metadata file that is used for automated prompt generation and for capturing image context. The codebase outputs 3-4 enriched images based on the model selected (Stable Diffusion XL or Imagen 2). This capability can be used by clients for background content generation to enhance product visuals by adding contextual elements, making them more engaging and informative. This capability can create relevant backgrounds that align with the product's use case and target audience. This saves time and resources while ensuring high-quality and consistent imagery. This can be leveraged by clients to produce captivating visuals that better connect with consumers. By transforming plain product images into contextual scenes, businesses can improve engagement and convey value more effectively, driving higher conversion rates and providing a competitive edge in the digital marketplace.

## Solution Architecture

The solution flow diagram is as follows:

1. SDXL Solution Flow:

<img src="artifacts/Solution Flow Chart/Slide1.JPG" width="800"/>

2. Imagen 2 Solution Flow

<img src="artifacts/Solution Flow Chart/Slide2.JPG" width="800"/>

The solution flow above describes the functions of the different modules present in the code and how they are used. The modules are as follows:-

1. Segmentation: This module is used for Image segmentation i.e. mask creation for segregating the object from its background. It uses SAM Predictor to generate the image mask.
2. Text Prompt for Inpainting: This module is used for generation of prompts that are used for background generation. This module generates the prompt by referencing a product metadata file and fixed prompt templates that are passed through Gemini model to get the final prompts.
3. Image Generation: This module generates the background for the image using models like Imagen 2 or Stable Diffusion XL. It uses manual prompts passed directly by the user or the prompts generated by Gemini in the text prompt module.

## Models Used

Models used in different modules are as follows:-

1. Segment Anything Model (SAM): Developed by Meta AI, this model is used for mask generation and image segmentation.
2. Stable Diffusion XL (SDXL): Developed by Stability AI, this model is used for background generation and image enrichment. It uses the image mask and prompt for background generation.
3. Imagen 2: Developed by Google Deepmind, this model avaiable on Vertex AI generates the image background directly from the prompt without the need of an image mask.
4. Gemini 2/PaLM 2: Developed by Google Gemini, Gemini 2 and PaLM are the LLM models that we are using for prompt generation using the product metadata details.

## Results

The following images are examples of the comparison of the original images, the generated images and the website image considering the context of the use of the product.

<table>
  <tr>
    <td><b>Original Image</b></td>
    <td><b>Generated Image</b></td>
    <td><b>Website Image</b></td>
  </tr>
  <tr>
    <td><img src="artifacts/D443144S_1.jpg" width="250"/></td>
    <td><img src="artifacts/Screenshot 2024-07-16 140110.png" width="250"/></td>
    <td><img src="artifacts/D443144S_2.jpg" width="250"/></td>
  </tr>
</table>

<table>
  <tr>
    <td><b>Original Image</b></td>
    <td><b>Generated Image</b></td>
    <td><b>Website Image</b></td>
  </tr>
  <tr>
    <td><img src="artifacts/M10194068.jpg" width="250"/></td>
    <td><img src="artifacts/M10194068_60.jpg" width="250"/></td>
    <td><img src="artifacts/10194068_25.jpg" width="250"/></td>
  </tr>
</table>

## Installation

The following commands can be used to setup the project:-

```bash
# Clone the git repository
git clone image-enrichment.git

# Install the dependencies
pip install -r requirements.txt

## Usage
python main.py

```

You can also use the Main.ipynb notebook to execute the same code in a step-by-step manner.
